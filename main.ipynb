{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "from surprise import accuracy\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# \n",
    "\n",
    "files_dir = os.path.expanduser('dataset/')\n",
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "train_file = files_dir + 'train-50-%d.csv'\n",
    "test_file = files_dir + 'test-50-%d.csv'\n",
    "folds_files = [(train_file % i, test_file % i) for i in (1, 2, 3, 4, 5)]\n",
    "\n",
    "data = Dataset.load_from_folds(folds_files, reader=reader)\n",
    "pkf = PredefinedKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 6040 is out of bounds for axis 0 with size 6040",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09248904ddc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_iid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0midcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtestscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mndcgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0midcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6040 is out of bounds for axis 0 with size 6040"
     ]
    }
   ],
   "source": [
    "#Start Training\n",
    "\n",
    "i = 1\n",
    "for trainset, testset in pkf.split(data): \n",
    "    # create test matrix\n",
    "    test_matrix = np.zeros((6040, 4000))\n",
    "    for row in testset:\n",
    "        test_matrix[int(row[0])-1, int(row[1])-1] = int(row[2])\n",
    "    \n",
    "    # train and test algorithm.\n",
    "    svd.fit(trainset)\n",
    "    \n",
    "    # create recommendations' container\n",
    "    recs = np.zeros((len(svd.trainset.all_users()), len(svd.trainset.all_items())))\n",
    "    \n",
    "    # make pearson correlation among users\n",
    "    corr = np.corrcoef(svd.pu)\n",
    "    \n",
    "    # sort the correlations, get the sorted ids\n",
    "    sim_score_user_indices = np.argsort(-corr)\n",
    "    \n",
    "    # for each user, compute recommendation ranking\n",
    "    for user_id in range(len(test_matrix)):\n",
    "        # check if user is available\n",
    "        if svd.trainset.knows_user(user_id):\n",
    "        \n",
    "            # get 10 most similar users to user target\n",
    "            sim_user_ids = sim_score_user_indices[user_id][1:k + 1]\n",
    "\n",
    "            # create similar users container\n",
    "            similar_users = np.empty([1, len(svd.trainset.all_items())])\n",
    "\n",
    "            # compute similar users' rating values\n",
    "            for sim_user_id in sim_user_ids:\n",
    "                similar_users = np.append(similar_users, [svd.trainset.global_mean + svd.bu[sim_user_id] + svd.bi + np.dot(svd.qi, svd.pu[sim_user_id])], axis=0)\n",
    "            similar_users = np.delete(similar_users, 0, axis=0)\n",
    "\n",
    "            # compute scores of each user\n",
    "            scores = np.tile(np.arange(0, len(svd.trainset.all_items()))[::-1], (10,1)) - np.tile(np.arange(0, len(svd.trainset.all_items())), (10,1))\n",
    "            for index, value in enumerate(np.argsort(-similar_users)):\n",
    "                scores[index] = scores[index, value]\n",
    "\n",
    "            # compute recommendation ranking by aggregating then sorting the scores\n",
    "            recs[user_id] = np.argsort(-np.sum(scores, axis=0))\n",
    "        else:\n",
    "            all_users = (np.dot(svd.pu, svd.qi.transpose()).transpose() + svd.bu).transpose() + svd.bi + svd.trainset.global_mean\n",
    "            scores = np.tile(np.arange(0,len(svd.trainset.all_items()))[::-1], (len(svd.trainset.all_users()),1)) - np.tile(np.arange(0,len(svd.trainset.all_items())), (len(svd.trainset.all_users()),1))\n",
    "            for index, value in enumerate(np.argsort(-all_users)):\n",
    "                scores[index] = scores[index, value]\n",
    "                \n",
    "            # compute recommendation ranking by aggregating then sorting the scores\n",
    "            recs[user_id] = np.argsort(-np.sum(scores, axis=0))\n",
    "    # evaluate\n",
    "    testscores = np.tile(np.arange(1, 4001)[::-1], (6040,1))\n",
    "    for index, _ in enumerate(testscores):\n",
    "        testscores[index] = testscores[index, np.argsort(np.argsort(-test_matrix[index]))]\n",
    "\n",
    "    ndcgs = []\n",
    "    for index, value in enumerate(recs):\n",
    "        rank = []\n",
    "        for item in value[:10]:\n",
    "            rank.append(int(svd.trainset.to_raw_iid(item)))\n",
    "        dcg = np.sum(testscores[int(svd.trainset.to_raw_uid(index)), rank] / np.log2(np.arange(1,11) + 1))\n",
    "        idcg = np.sum(-np.sort(-testscores[int(svd.trainset.to_raw_uid(index)), rank]) / np.log2(np.arange(1,11) + 1))\n",
    "        ndcgs.append(dcg/idcg)\n",
    "\n",
    "    print(\"ndcgs fold-{} = {}\".format(i, np.mean(ndcgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}